import { smoothStream, streamText } from "ai";

import { customModelProvider } from "lib/ai/models";
import { CREATE_THREAD_TITLE_PROMPT } from "lib/ai/prompts";
import globalLogger from "logger";
import { ChatModel } from "app-types/chat";
import { chatRepository, userRepository } from "lib/db/repository";
import { getSession } from "auth/server";
import { colorize } from "consola/utils";
import { handleError } from "../shared.chat";

const logger = globalLogger.withDefaults({
  message: colorize("blackBright", `Title API: `),
});

export async function POST(request: Request) {
  try {
    const json = await request.json();

    const {
      chatModel,
      message = "hello",
      threadId,
    } = json as {
      chatModel?: ChatModel;
      message: string;
      threadId: string;
    };

    const session = await getSession();
    if (!session) {
      return new Response("Unauthorized", { status: 401 });
    }

    const preferences = await userRepository.getPreferences(session.user.id);
    const resolvedModel: ChatModel | undefined =
      preferences?.botSecretaryModel ?? chatModel;

    logger.info(
      `chatModel: ${resolvedModel?.provider}/${resolvedModel?.model}, threadId: ${threadId}`,
    );

    // conversation title should be generated by a third-party model
    if (resolvedModel?.provider === "dify") {
      // conversation title should NOT be generated by Dify
      const result = streamText({
        model: await customModelProvider.getModel(resolvedModel),
        experimental_transform: smoothStream({ chunking: "word" }),
        prompt: message + "\n\n" + CREATE_THREAD_TITLE_PROMPT,
        abortSignal: request.signal,
        // add user-id in header for Dify at least
        headers: {
          "user-id": session.user.email,
        },
        onFinish: (ctx) => {
          chatRepository
            .upsertThread({
              id: threadId,
              title: ctx.text,
              userId: session.user.id,
            })
            .catch((err) => logger.error(err));
        },
      });

      return result.toUIMessageStreamResponse();
    } else {
      const result = streamText({
        model: await customModelProvider.getModel(resolvedModel),
        system: CREATE_THREAD_TITLE_PROMPT,
        experimental_transform: smoothStream({ chunking: "word" }),
        prompt: message,
        abortSignal: request.signal,
        onFinish: (ctx) => {
          chatRepository
            .upsertThread({
              id: threadId,
              title: ctx.text,
              userId: session.user.id,
            })
            .catch((err) => logger.error(err));
        },
      });

      return result.toUIMessageStreamResponse();
    }
  } catch (err) {
    return new Response(handleError(err), { status: 500 });
  }
}
